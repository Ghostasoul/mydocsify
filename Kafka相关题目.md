### 1. 使用消息队列的主要目的：解耦、异步、削峰填谷

解耦：在一个复杂的系统中，不同的模块或服务之间可能需要互相依赖，如果直接使用函数调用或者API调用的方式，会造成模块之间的耦合，当其中一个模块发生改变时，需要同时修改调用方和被调用方的代码。而使用消息队列作为中间件，不同的模块可以将消息发送到消息队列中，不需要知道具体的接收方是谁，接收方可以独立的消费消息，实现了模块之间的解耦。

异步：有些操作比较耗时，例如发送邮件、生成报表等，如果使用同步的方式处理，会阻塞主线程或者进程，导致系统的性能下降。而使用消息队列，可以讲这些操作封装成消息，放入消息队列中，异步处理这些操作，不影响主流程的执行，提高了系统的性能和相应速度。

削峰填谷：

### 2. Kafka为什么这么快？

消息发送：

1. 批量发送：Kafka通过将多个消息打包成一个批次，减少了网络传输和磁盘写入的次数，从而提高了消息的吞吐量和传输效率。
2. 异步发送 ：生产者可以异步发送消息，不必等待每个消息的确认，这大大提高了消息发送的效率。
3. 消息压缩：支持对消息进行压缩，减少网络传输的数据量。
4. 并行发送：通过将数据分布在不同的分区（Partitions）中，生产者可以并行发送消息，从而提高了吞吐量。

消息存储：

1. 零拷贝技术：Kafka使用零拷贝技术来避免了数据的拷贝操作，降低了内存和CPU的使用率，提高了系统的性能。
2. 磁盘顺序写入：Kafka把消息存储在磁盘上，且以顺序的方式写入数据。顺序写入比随机写入速度快很多，因为它减少了磁头寻道时间。避免了随机读写带来的性能损耗，提高了磁盘的使用效率。
3. 页缓存：Kafka将其数据存储在磁盘中，但在访问数据时，它会先将数据加载到操作系统的页缓存中，并在页缓存中保留一份副本，从而实现快速的数据访问。
4. 稀疏索引：
5. 分区和副本：

消息消费：
1. 消费者群组：通过消费者群组可以实现消息的负载均衡和容错处理。
2. 并行消费：不同的消费者可以独立的消费不同的分区，实现消费的并行处理。
3. 批量拉取：Kafka支持批量拉取消息，可以一次性拉取多个消息进行消费。减少网络消耗，提升性能。

### 3. Kafka的架构是怎么样的？

显式分布式架构，主要由Producer（生产者）、broker（kafka集群）和consumer（消费者）组成。![截屏2024-02-21 17.32.02](https://qcloudtest-1256407512.cos.ap-guangzhou.myqcloud.com/Pic%E6%88%AA%E5%B1%8F2024-06-22%2014.33.25.png)

### 4. Kafka为什么有Topic还要用Partition？

>主题：Topic是Kafka中承载消息的逻辑容器。可以理解为一个消息队列。生产者将消息发送到特定的Topic，消费者从Topic中读取消息。Topic可以被认为是逻辑上的消息流。在实际使用中多用来区分具体的业务。
>
>分区：Partition。是Topic的物理分区。一个Topic可以被分成多个Partition，每个Partition是一个有序且持久化存储的日志文件。每个Partition都存储了一部分消息，并且有一个唯一的标识符（称为Partition ID）。

好处：

1. 提升吞吐量：
2. 负载均衡：
3. 扩展性：

综上所述，Topic是逻辑上的消息分类，而Partition是物理上的消息分区。通过将Topic分成多个Partition，可以实现提升吞吐量、负载均衡、以及增加可扩展性。

### 5. Kafka如何保证消息不丢失？

一次消息发送包含以下三个过程：

1. Producer端发送消息给Kafka Broker。
2. Kafka Broker将消息进行同步并持久化数据。
3. Consumer端从Kafka Broker将消息拉取并进行消费。

Kafka只对已经提交的消息做最大限度的持久化保证不丢失，但是没办法保证100%。

从生产者、消费者以及Kafka集群三个方面来分析

##### Producer

消息的生产者端，最怕就是消息发送给Kafka集群的过程中失败，所以，需要有机制来确保消息能够发送成功，但是，因为网络的问题，基本没办法可以保证一次消息一定成功。

所以，需要有一个确认机制来告诉生产者这个消息是否发送成功，如果没成功，需要重新发送直到成功。

使用Kafka发送消息的时候，通常使用producer.send(msg)其实是一种异步发送，发送消息的时候，方法会立即返回，但是并不代表消息一定能发送成功。（producer.send(msg).get()）是同步等待返回的。

为了保证消息不丢失，通过会建议使用producer.send(msg,callback)方法，这个方法支持传入一个callback，可以在消息发送失败时进行重试。

同时，可以通过给producer设置一些参数来提升发送的成功率。

```text
acks=-1  //表示Leader和Follower都接受成功时确认；可以最大限度保证消息不丢失，但是吞吐量低。
retries=3 //生产端的重试次数
retry.backoff.ms=300 //消息发送超时或失败后，间隔的重试时间。
```



##### Broker

##### Consumer

### 6. 为什么Kafka没办法100%保证消息不丢失？

Kafka提供的Producer和Consumer之间的消息传递保证语义有三种，所谓消息传递语义，其实就是Kafka的消息交付可靠保障，主要有以下三种：

* At most once---消息可能会丢失，但绝不会重复传递
* At least once---消息绝不会丢失，但可能会重复传递
* Exactly once---每条消息只会被精准地传递一次：既不会多，也不会少

目前，Kafka默认提供的交付可靠性保障性是第二种，即At least once，但是，其实依靠Kafka自身，是没有办法100%保证可靠性的。

原因：

生产者：

消费者：

Broker：

### 7. Kafka如何实现顺序消费？
#### 为什么同一个partition的消息是有序的？
Kafka的消息是存储在指定的topic中的某个partition中的。并且一个topic是可以有多个partition的，同一个partition中的消息是有序的，但是跨partition，或者跨topic的消息就是无序的了。
因为当生产者向某个partition发送消息的时候，消息会被追加到该partition的日志文件中，并且被分配一个唯一的offset，文件的读写是有顺序的。而消费者在从该分区消费消息时，会从该分区的最早offset开始逐个读取消息，保证了消息的顺序性。
#### 基于此，要想实现消息的顺序消费，可以有以下几个办法：
1. 在一个topic中，只创建一个partition，这样这个topic下的消息都会按照顺序保存在同一个partition中，这就保证了消息的顺序消费。
2. 发送消息的时候指定partition，如果一个topic下有多个partition，那么可以把需要保证顺序的消息都发送到同一个partition中，这样也能做到顺序消费。

### 8. Kafka怎样保证消费只消费一次的？

Kafka消息只消费一次，这个需要从多个方面回答，既包含Kafka自身的机制，也需要考虑客户端自己的重复处理。



### 9. 介绍下Kafka的ISR（副本同步列表）机制？



### 10. Kafka的同步和异步发送

Kafka对于消息的发送，可以支持同步和异步。同步会阻塞，而异步不需要等待阻塞的过程。从本质上来说，Kafka都是采用异步的方式来发送消息到broker，但是Kafka并不是每次发送消息都会直接发送到broker上，而是把消息放到了一个发送队列中，然后通过一个后台线程不断从队列取出消息进行发送，发送成功会出发callback。Kafka服务端会积累一定量的消息统一组装成一个批量消息发送出去，出发条件是batch.size和linger.ms

### 11. Kafka生产真实案例---生产者阻塞事件

 

### 12. Kafka消费积压百万数据怎么办？

1. ##### 背景：

   某一天下午三点业务高峰期，突然收到系统告警，告警信息如下：

   【告警分析通知】

   告警时间：

   目标名称：

   告警信息：

   阈值类型：

   阈值ID：

   系统编码：

   主运维：

   主机IP：

   对象名称：

   原因分析：

2. ##### 问题排查：

   从这个告警消息可以看出，dance-member-service模块消费kafka对应的topic：topic——integral消息出现大量积压，导致消息积压的原因常见的有两种：

   1. 生产消息过快
   2. 消费速率过慢

   一般可以检查消费端日志，是否有大量报错，另外通过监控系统的dump文件，查看耗时比较久的线程，有针对性优化代码：比如后边发现，采用hutool组件的JSONUtil.toList()方法，这个方法在高并发下性能非常差。

3. ##### 解决方案：

   消费端：优化消费端代码、自动提交改为手动提交、单条消费消息改为批量消费消息，数据单条入库改为批量入库、消费逻辑涉及DB操作，第一时间是否有慢SQL，通过explain分析是否可以通过加索引解决（大表要考虑是否会锁表，尽可能低峰期操作）

   broker端：kafka partition分区数>应用消费节点，可以扩broker分区数，否则，扩broker分区数没用（应急：优先扩节点）例如：应用节点12，broker分区数：16，扩broker分区数是否有用？答案：没用。应用节点24个，broker分区数：16，扩broker分区数是否有用？答案：有用，有8个应用节点处于空闲状态，扩8个节点，消费能力明显增强。

   生产端：针对生产端采用动态配置开关降级，关闭MQ生产（系统不能快速扩容）、消费端消息没有积压后，通过消息补偿程序对业务消息补偿，同时消费端需要支持幂等。

   大促前的相关预案：1.支持动态扩容。2.配置开关动态关闭生产端。3.配置开关动态关闭消费端。4.生产端支持消息补偿。5.消费端支持消息幂等。

### 13. 当线上Kafka集群有大量消息积压时，如何利用多线程消费解决积压问题。

https://blog.csdn.net/RIGHTSONG/article/details/114839511
